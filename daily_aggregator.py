#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ—¥æ¬¡é›†è¨ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
Google Driveä¸Šã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å½“æ—¥ã®VCãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’é›†è¨ˆã—ã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®çµ±è¨ˆæƒ…å ±ã‚’Google Sheetsã«æ›¸ãè¾¼ã‚€
"""

import os
import sys
import json
import base64
import argparse
from datetime import datetime, timedelta, date
from typing import Dict, List, Optional, Any
from collections import defaultdict
import io
from loguru import logger

# Google Drive/Sheets APIé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from googleapiclient.errors import HttpError

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
from dotenv import load_dotenv
load_dotenv()

# config.pyã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
from config import EnvConfig, Environment

# loguruã®è¨­å®š
logger.remove()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’å‰Šé™¤
logger.add(sys.stderr, level="INFO", format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message} | {name}.py | def: {function}")  # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã¨é–¢æ•°åä»˜ãï¼‰

# logsãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
os.makedirs("logs", exist_ok=True)  # logsãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰

# ç¾åœ¨ã®æ—¥ä»˜ã‚’å–å¾—ï¼ˆYYYYMMDDå½¢å¼ï¼‰
current_date = datetime.now().strftime("%Y%m%d")  # æ—¥ä»˜å–å¾—

# å‡¦ç†åˆ¥ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
# 1. ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®ãƒ­ã‚°
logger.add(f"logs/daily_aggregator_{current_date}.log",
          rotation="10 MB",
          retention="7 days",
          level="INFO",
          encoding="utf-8",
          format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message} | {name}.py | def: {function}",
          filter=lambda record: "get_csv" not in record["function"] and "aggregate" not in record["function"])  # ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ­ã‚°

# 2. CSVãƒ•ã‚¡ã‚¤ãƒ«å–å¾—å‡¦ç†ã®ãƒ­ã‚°
logger.add(f"logs/csv_fetch_{current_date}.log",
          rotation="10 MB",
          retention="7 days",
          level="DEBUG",
          encoding="utf-8",
          format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message} | {name}.py | def: {function}",
          filter=lambda record: "get_csv" in record["function"] or "read_csv" in record["function"])  # CSVå–å¾—ãƒ­ã‚°

# 3. é›†è¨ˆå‡¦ç†ã®ãƒ­ã‚°
logger.add(f"logs/aggregation_{current_date}.log",
          rotation="10 MB",
          retention="7 days",
          level="INFO",
          encoding="utf-8",
          format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message} | {name}.py | def: {function}",
          filter=lambda record: "aggregate" in record["function"] or "write" in record["function"] or "update" in record["function"])  # é›†è¨ˆå‡¦ç†ãƒ­ã‚°

# 4. ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ï¼ˆå…¨ã¦ã®ã‚¨ãƒ©ãƒ¼ã‚’è¨˜éŒ²ï¼‰
logger.add(f"logs/error_{current_date}.log",
          rotation="10 MB",
          retention="30 days",
          level="ERROR",
          encoding="utf-8",
          format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}.py | def: {function} | {message}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°


class DailyAggregator:
    """æ—¥æ¬¡é›†è¨ˆå‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, target_date: Optional[date] = None, env: Environment = Environment.PRD, output_pattern: str = 'slack'):
        """
        åˆæœŸåŒ–

        Args:
            target_date: é›†è¨ˆå¯¾è±¡æ—¥ï¼ˆNoneã®å ´åˆã¯ä»Šæ—¥ï¼‰
            env: å®Ÿè¡Œç’°å¢ƒ
            output_pattern: å‡ºåŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ ('discord' or 'slack')
        """
        self.target_date = target_date or date.today()  # é›†è¨ˆå¯¾è±¡æ—¥
        self.env = env  # å®Ÿè¡Œç’°å¢ƒ
        self.output_pattern = output_pattern  # å‡ºåŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.drive_service = None  # Google Drive APIã‚µãƒ¼ãƒ“ã‚¹
        self.sheets_service = None  # Google Sheets APIã‚µãƒ¼ãƒ“ã‚¹
        self.credentials = None  # èªè¨¼æƒ…å ±
        self.user_mapping = {}  # Discordåâ†’Slackåã®ãƒãƒƒãƒ”ãƒ³ã‚°

        # config.pyã‹ã‚‰è¨­å®šã‚’å–å¾—
        sheets_config = EnvConfig.get_google_sheets_config(env)  # Google Sheetsè¨­å®šå–å¾—
        drive_config = EnvConfig.get_google_drive_config(env)  # Google Driveè¨­å®šå–å¾—
        discord_config = EnvConfig.get_discord_config(env)  # Discordè¨­å®šå–å¾—

        self.sheet_name = sheets_config.get('sheet_name', 'VC_Tracker_Database')  # Sheetså
        self.folder_path = drive_config.get('folder_path', 'discord_mokumoku_tracker')  # ãƒ™ãƒ¼ã‚¹ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ï¼ˆcsvã‚’é™¤ãï¼‰
        self.allowed_vc_ids = discord_config.get('channel_ids', [])  # å¯¾è±¡VCãƒãƒ£ãƒ³ãƒãƒ«ID
        self.env_number = drive_config.get('env_number', '2')  # ç’°å¢ƒç•ªå·å–å¾—
        self.env_name = drive_config.get('env_name', 'DEV')  # ç’°å¢ƒåå–å¾—

        # åˆæœŸåŒ–å‡¦ç†
        self._initialize_services()


    def _initialize_services(self):
        """Google API ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–"""
        try:
            # èªè¨¼æƒ…å ±ã®å–å¾—
            self.credentials = self._get_credentials()

            # Drive APIã‚µãƒ¼ãƒ“ã‚¹ã®æ§‹ç¯‰
            self.drive_service = build('drive', 'v3', credentials=self.credentials)
            logger.info("ğŸ“ Google Driveã¸ã®æ¥ç¶šãŒå®Œäº†ã—ã¾ã—ãŸ")  # åˆæœŸåŒ–æˆåŠŸãƒ­ã‚°

            # Sheets APIã‚µãƒ¼ãƒ“ã‚¹ã®æ§‹ç¯‰
            self.sheets_service = build('sheets', 'v4', credentials=self.credentials)
            logger.info("ğŸ“Š Google Sheetsã¸ã®æ¥ç¶šãŒå®Œäº†ã—ã¾ã—ãŸ")  # åˆæœŸåŒ–æˆåŠŸãƒ­ã‚°

        except Exception as e:
            logger.error(f"âš ï¸ ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            raise

    def _get_credentials(self):
        """èªè¨¼æƒ…å ±ã‚’å–å¾—"""
        # config.pyã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        sheets_config = EnvConfig.get_google_sheets_config(self.env)  # Google Sheetsè¨­å®šå–å¾—
        service_account_json_base64 = sheets_config.get('service_account_json_base64')  # Base64èªè¨¼æƒ…å ±
        service_account_file = sheets_config.get('service_account_json')  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        if service_account_json_base64:
            # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
            service_account_json = base64.b64decode(service_account_json_base64).decode('utf-8')
            service_account_info = json.loads(service_account_json)
            logger.info("ğŸ” ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸï¼ˆBase64å½¢å¼ï¼‰")  # Base64èªè¨¼ä½¿ç”¨ãƒ­ã‚°
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿
            if not os.path.exists(service_account_file):
                raise FileNotFoundError(f"Service account file not found: {service_account_file}")
            with open(service_account_file, 'r') as f:
                service_account_info = json.load(f)
            logger.info(f"ğŸ” èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {service_account_file}")  # ãƒ•ã‚¡ã‚¤ãƒ«èªè¨¼ä½¿ç”¨ãƒ­ã‚°

        # ã‚¹ã‚³ãƒ¼ãƒ—è¨­å®š
        scopes = [
            'https://www.googleapis.com/auth/drive',
            'https://www.googleapis.com/auth/spreadsheets'
        ]

        # èªè¨¼æƒ…å ±ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        return service_account.Credentials.from_service_account_info(
            service_account_info,
            scopes=scopes
        )

    def get_csv_files_from_drive(self) -> List[Dict[str, str]]:
        """
        Google Driveã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—

        Returns:
            CSVãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ãƒªã‚¹ãƒˆ [{id, name}, ...]
        """
        try:
            logger.info(f"ğŸ” CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ã‚’é–‹å§‹ã—ã¾ã™")  # æ¤œç´¢é–‹å§‹ãƒ­ã‚°
            logger.info(f"ğŸ“ æ¤œç´¢ãƒ‘ã‚¹: {self.folder_path}")  # æ¤œç´¢ãƒ‘ã‚¹è¡¨ç¤º

            # ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰ãƒ•ã‚©ãƒ«ãƒ€éšå±¤ã‚’å–å¾—
            folder_parts = self.folder_path.split('/')  # ãƒ‘ã‚¹ã‚’åˆ†å‰²
            if not folder_parts:
                logger.warning("âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ãŒç„¡åŠ¹ã§ã™")  # ç„¡åŠ¹ãªãƒ‘ã‚¹è­¦å‘Š
                return []

            # ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢ï¼ˆå…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–å¯¾å¿œï¼‰
            root_folder_name = folder_parts[0]  # ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€å
            folder_query = f"name='{root_folder_name}' and mimeType='application/vnd.google-apps.folder'"
            folder_results = self.drive_service.files().list(
                q=folder_query,
                fields="files(id, name)",
                supportsAllDrives=True,
                includeItemsFromAllDrives=True,
                corpora='allDrives'
            ).execute()

            folders = folder_results.get('files', [])
            if not folders:
                logger.warning(f"âš ï¸ Google Driveä¸Šã« '{root_folder_name}' ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")  # ãƒ•ã‚©ãƒ«ãƒ€æœªç™ºè¦‹è­¦å‘Š
                return []

            folder_id = folders[0]['id']  # ãƒ•ã‚©ãƒ«ãƒ€IDå–å¾—
            logger.info(f"ğŸ“‚ ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç™ºè¦‹: {folders[0]['name']}")  # ãƒ•ã‚©ãƒ«ãƒ€ç™ºè¦‹ãƒ­ã‚°

            # æ®‹ã‚Šã®ãƒ•ã‚©ãƒ«ãƒ€éšå±¤ã‚’é †ã«æ¢ç´¢
            current_folder_id = folder_id
            for folder_name in folder_parts[1:]:
                subfolder_query = f"'{current_folder_id}' in parents and name='{folder_name}' and mimeType='application/vnd.google-apps.folder'"
                subfolder_results = self.drive_service.files().list(
                    q=subfolder_query,
                    fields="files(id, name)",
                    supportsAllDrives=True,
                    includeItemsFromAllDrives=True
                ).execute()

                subfolders = subfolder_results.get('files', [])
                if not subfolders:
                    logger.warning(f"âš ï¸ ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ '{folder_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")  # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€æœªç™ºè¦‹è­¦å‘Š
                    return []

                current_folder_id = subfolders[0]['id']  # æ¬¡ã®ãƒ•ã‚©ãƒ«ãƒ€ID
                logger.info(f"ğŸ“‚ ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç™ºè¦‹: {folder_name}")  # ãƒ•ã‚©ãƒ«ãƒ€ç™ºè¦‹ãƒ­ã‚°

            # æœ€çµ‚çš„ãªãƒ•ã‚©ãƒ«ãƒ€IDã‚’ä¿å­˜ï¼ˆdiscord_mokumoku_trackerãƒ•ã‚©ãƒ«ãƒ€ï¼‰
            base_folder_id = current_folder_id

            # discord_mokumoku_trackerå†…ã®VCãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢
            full_path = '/'.join(folder_parts)  # å®Œå…¨ãªãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            logger.info(f"ğŸ“‚ ç¾åœ¨ã®ãƒ•ã‚©ãƒ«ãƒ€: {full_path}")  # ç¾åœ¨ä½ç½®ãƒ­ã‚°
            logger.info(f"ğŸ” VCãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢ä¸­...")  # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚©ãƒ«ãƒ€æ¤œç´¢ãƒ­ã‚°
            channel_folder_query = f"'{base_folder_id}' in parents and mimeType='application/vnd.google-apps.folder'"
            channel_folder_results = self.drive_service.files().list(
                q=channel_folder_query,
                fields="files(id, name)",
                supportsAllDrives=True,
                includeItemsFromAllDrives=True
            ).execute()

            channel_folders = channel_folder_results.get('files', [])
            logger.info(f"ğŸ“ {len(channel_folders)}å€‹ã®VCãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ")  # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚©ãƒ«ãƒ€æ•°ãƒ­ã‚°
            if channel_folders:
                logger.info(f"ğŸ“ ç™ºè¦‹ã—ãŸãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚©ãƒ«ãƒ€: {', '.join([f['name'] for f in channel_folders])}")  # ãƒãƒ£ãƒ³ãƒãƒ«åä¸€è¦§

            csv_files = []
            # å„VCãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚©ãƒ«ãƒ€å†…ã®csvã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢
            for channel_folder in channel_folders:
                channel_folder_id = channel_folder['id']
                channel_name = channel_folder['name']

                # csvã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢
                csv_folder_query = f"'{channel_folder_id}' in parents and name='csv' and mimeType='application/vnd.google-apps.folder'"
                csv_folder_results = self.drive_service.files().list(
                    q=csv_folder_query,
                    fields="files(id, name)",
                    supportsAllDrives=True,
                    includeItemsFromAllDrives=True
                ).execute()

                csv_folders = csv_folder_results.get('files', [])
                if not csv_folders:
                    logger.info(f"  â„¹ï¸ {channel_name}ãƒ•ã‚©ãƒ«ãƒ€å†…ã«csvãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã›ã‚“")  # csvãƒ•ã‚©ãƒ«ãƒ€ãªã—ãƒ­ã‚°
                    continue

                csv_folder_id = csv_folders[0]['id']

                # csvãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç’°å¢ƒã«å¿œã˜ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
                target_csv_name = f"{self.env_number}_{self.env_name}.csv"  # å¯¾è±¡CSVãƒ•ã‚¡ã‚¤ãƒ«å
                search_path = f"{full_path}/{channel_name}/csv/{target_csv_name}"  # æ¤œç´¢ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
                logger.debug(f"ğŸ” CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­: {search_path}")  # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
                csv_query = f"'{csv_folder_id}' in parents and name='{target_csv_name}'"
                csv_results = self.drive_service.files().list(
                    q=csv_query,
                    fields="files(id, name)",
                    supportsAllDrives=True,
                    includeItemsFromAllDrives=True
                ).execute()

                channel_csv_files = csv_results.get('files', [])
                csv_files.extend(channel_csv_files)
                if channel_csv_files:
                    for csv_file in channel_csv_files:
                        logger.debug(f"  âœ… ç™ºè¦‹: {search_path}")  # CSVãƒ•ã‚¡ã‚¤ãƒ«åè¡¨ç¤º
                        logger.info(f"  âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹: {search_path}")  # CSVãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹é€šçŸ¥
                else:
                    logger.debug(f"  âš ï¸ {target_csv_name}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")  # CSVãƒ•ã‚¡ã‚¤ãƒ«ãªã—ãƒ­ã‚°
                    logger.info(f"  â„¹ï¸ {channel_name}/csvãƒ•ã‚©ãƒ«ãƒ€å†…ã«{target_csv_name}ãŒã‚ã‚Šã¾ã›ã‚“")  # è©³ç´°æƒ…å ±
            logger.info(f"ğŸ“ åˆè¨ˆ{len(csv_files)}å€‹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ")  # CSVãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒ­ã‚°

            return csv_files

        except HttpError as e:
            logger.error(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            return []

    def read_csv_content(self, file_id: str, file_name: str) -> List[Dict[str, str]]:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿

        Args:
            file_id: ãƒ•ã‚¡ã‚¤ãƒ«ID
            file_name: ãƒ•ã‚¡ã‚¤ãƒ«å

        Returns:
            CSVãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
        """
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            request = self.drive_service.files().get_media(fileId=file_id)
            file_content = io.BytesIO()
            downloader = MediaIoBaseDownload(file_content, request)

            done = False
            while not done:
                status, done = downloader.next_chunk()

            # CSVã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆBOMã‚’é™¤å»ï¼‰
            file_content.seek(0)
            csv_text = file_content.read().decode('utf-8-sig')  # BOMã‚’è‡ªå‹•é™¤å»

            if not csv_text:
                logger.warning(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {file_name}")  # ç©ºãƒ•ã‚¡ã‚¤ãƒ«è­¦å‘Š
                return []

            lines = csv_text.strip().split('\n')
            if len(lines) < 2:  # ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿ã®å ´åˆ
                return []

            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’å–å¾—ï¼ˆæ”¹è¡Œã‚³ãƒ¼ãƒ‰ã‚‚é™¤å»ï¼‰
            headers = [h.strip() for h in lines[0].split(',')]
            logger.debug(f"ğŸ“‹ CSVãƒ˜ãƒƒãƒ€ãƒ¼: {headers}")  # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ãƒ­ã‚°

            # æ—¥ä»˜åˆ—ã®ç¢ºèª
            if 'datetime_jst' in headers:
                logger.info(f"âœ… datetime_jståˆ—ã‚’ç™ºè¦‹ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {headers.index('datetime_jst')}ï¼‰")  # æ—¥ä»˜åˆ—ç¢ºèª
            else:
                logger.warning(f"âš ï¸ datetime_jståˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {headers}")  # æ—¥ä»˜åˆ—ãªã—è­¦å‘Š

            # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’ãƒ‘ãƒ¼ã‚¹
            records = []
            # ä¸¡æ–¹ã®æ—¥ä»˜å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆï¼ˆã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚ã‚Š/ãªã—ï¼‰
            target_date_str = self.target_date.strftime('%Y/%m/%d')  # å¯¾è±¡æ—¥ä»˜æ–‡å­—åˆ—ï¼ˆã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚ã‚Šï¼‰
            target_date_str_no_pad = self.target_date.strftime('%Y/%-m/%-d') if os.name != 'nt' else self.target_date.strftime('%Y/%#m/%#d')  # ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã—
            logger.info(f"ğŸ” æ¤œç´¢å¯¾è±¡æ—¥ä»˜: {target_date_str} ã¾ãŸã¯ {target_date_str_no_pad}")  # æ¤œç´¢æ—¥ä»˜ãƒ­ã‚°

            # æœ€åˆã®æ•°è¡Œã‚’ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
            sample_count = min(3, len(lines) - 1)  # æœ€å¤§3è¡Œè¡¨ç¤º
            if sample_count > 0:
                logger.debug(f"ğŸ“Š CSVãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®{sample_count}è¡Œï¼‰:")  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ˜ãƒƒãƒ€ãƒ¼

            for idx, line in enumerate(lines[1:]):
                values = line.split(',')
                if len(values) != len(headers):
                    continue

                record = dict(zip(headers, values))

                # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                if idx < sample_count:
                    if 'datetime_jst' in record:
                        logger.debug(f"  è¡Œ{idx+1}: datetime_jst='{record['datetime_jst']}'")  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                    else:
                        logger.debug(f"  è¡Œ{idx+1}: {record}")  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å…¨ä½“

                # å¯¾è±¡æ—¥ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿æŠ½å‡º
                if 'datetime_jst' in record:
                    datetime_value = record['datetime_jst'].strip()  # æ”¹è¡Œã‚³ãƒ¼ãƒ‰ç­‰ã‚’é™¤å»
                    # ä¸¡æ–¹ã®æ—¥ä»˜å½¢å¼ã§ãƒã‚§ãƒƒã‚¯
                    if datetime_value.startswith(target_date_str) or datetime_value.startswith(target_date_str_no_pad):
                        # VCãƒãƒ£ãƒ³ãƒãƒ«åã‚’è¿½åŠ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’é™¤ã„ãŸã‚‚ã®ï¼‰
                        record['vc_name'] = file_name.replace('.csv', '')
                        records.append(record)
                        logger.debug(f"  âœ… ãƒãƒƒãƒ: {datetime_value}")  # ãƒãƒƒãƒã—ãŸãƒ¬ã‚³ãƒ¼ãƒ‰

            logger.info(f"ğŸ“– {file_name}ã‹ã‚‰{target_date_str}ã®{len(records)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")  # èª­ã¿è¾¼ã¿çµæœãƒ­ã‚°
            return records

        except Exception as e:
            logger.error(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            return []

    def aggregate_user_data(self, all_records: List[Dict[str, str]]) -> Dict[str, Dict[str, Any]]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„

        Args:
            all_records: å…¨CSVãƒ¬ã‚³ãƒ¼ãƒ‰

        Returns:
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿
        """
        user_data = defaultdict(lambda: {
            'user_name': '',
            'vc_channels': set(),
            'login_count': 0
        })

        for record in all_records:
            # presentåˆ—ãŒå‰Šé™¤ã•ã‚ŒãŸãŸã‚ã€å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’é›†è¨ˆå¯¾è±¡ã¨ã™ã‚‹
            user_id = record.get('user_id', '')
            if user_id:
                user_data[user_id]['user_name'] = record.get('user_name', '')  # ãƒ¦ãƒ¼ã‚¶ãƒ¼å
                # vc_nameåˆ—ãŒãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰å–å¾—ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
                vc_name = record.get('vc_name', 'unknown')  # VCãƒãƒ£ãƒ³ãƒãƒ«å
                user_data[user_id]['vc_channels'].add(vc_name)  # VCãƒãƒ£ãƒ³ãƒãƒ«è¿½åŠ 
                user_data[user_id]['login_count'] += 1  # ãƒ­ã‚°ã‚¤ãƒ³å›æ•°ã‚«ã‚¦ãƒ³ãƒˆ

        # ã‚»ãƒƒãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        for user_id, data in user_data.items():
            data['vc_channels'] = ', '.join(sorted(data['vc_channels']))

        logger.info(f"ğŸ“ˆ {len(user_data)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆã—ã¾ã—ãŸ")  # é›†è¨ˆçµæœãƒ­ã‚°
        return dict(user_data)

    def get_sheet_id(self) -> Optional[str]:
        """Google Sheetsã®IDã‚’å–å¾—"""
        try:
            # Sheetsåã§æ¤œç´¢ï¼ˆå…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–å¯¾å¿œï¼‰
            query = f"name='{self.sheet_name}' and mimeType='application/vnd.google-apps.spreadsheet'"
            results = self.drive_service.files().list(
                q=query,
                fields="files(id, name)",
                supportsAllDrives=True,
                includeItemsFromAllDrives=True,
                corpora='allDrives'
            ).execute()

            sheets = results.get('files', [])
            if not sheets:
                logger.error(f"âš ï¸ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.sheet_name}")  # ã‚·ãƒ¼ãƒˆæœªç™ºè¦‹ã‚¨ãƒ©ãƒ¼
                return None

            sheet_id = sheets[0]['id']
            logger.info(f"ğŸ“Š ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ç™ºè¦‹: {self.sheet_name}")  # ã‚·ãƒ¼ãƒˆç™ºè¦‹ãƒ­ã‚°
            return sheet_id

        except Exception as e:
            logger.error(f"âš ï¸ ã‚·ãƒ¼ãƒˆIDã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            return None

    def ensure_sheets_exist(self, sheet_id: str):
        """å¿…è¦ãªã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€ãªã‘ã‚Œã°ä½œæˆ"""
        try:
            # æ—¢å­˜ã®ã‚·ãƒ¼ãƒˆä¸€è¦§ã‚’å–å¾—
            spreadsheet = self.sheets_service.spreadsheets().get(
                spreadsheetId=sheet_id
            ).execute()

            existing_sheets = [sheet['properties']['title'] for sheet in spreadsheet['sheets']]

            # å¿…è¦ãªã‚·ãƒ¼ãƒˆå
            required_sheets = ['daily_summary', 'user_statistics']

            # ä¸è¶³ã—ã¦ã„ã‚‹ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ
            requests = []
            for sheet_name in required_sheets:
                if sheet_name not in existing_sheets:
                    requests.append({
                        'addSheet': {
                            'properties': {
                                'title': sheet_name
                            }
                        }
                    })
                    logger.info(f"ğŸ“„ æ–°ã—ã„ã‚·ãƒ¼ãƒˆã‚’ä½œæˆä¸­: {sheet_name}")  # ã‚·ãƒ¼ãƒˆä½œæˆãƒ­ã‚°

            if requests:
                self.sheets_service.spreadsheets().batchUpdate(
                    spreadsheetId=sheet_id,
                    body={'requests': requests}
                ).execute()

                # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®š
                self._set_sheet_headers(sheet_id)

        except Exception as e:
            logger.error(f"âš ï¸ ã‚·ãƒ¼ãƒˆã®ç¢ºèªãƒ»ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            raise

    def _set_sheet_headers(self, sheet_id: str):
        """ã‚·ãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®š"""
        try:
            # daily_summaryã®ãƒ˜ãƒƒãƒ€ãƒ¼
            daily_headers = [['date', 'user_id', 'user_name', 'vc_channels', 'login_count']]
            self.sheets_service.spreadsheets().values().update(
                spreadsheetId=sheet_id,
                range='daily_summary!A1:E1',
                valueInputOption='RAW',
                body={'values': daily_headers}
            ).execute()

            # user_statisticsã®ãƒ˜ãƒƒãƒ€ãƒ¼
            stats_headers = [['user_id', 'user_name', 'last_login_date', 'consecutive_days',
                             'monthly_days', 'total_days', 'last_updated']]
            self.sheets_service.spreadsheets().values().update(
                spreadsheetId=sheet_id,
                range='user_statistics!A1:G1',
                valueInputOption='RAW',
                body={'values': stats_headers}
            ).execute()

            logger.info("âœ… ã‚·ãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šã—ã¾ã—ãŸ")  # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®šæˆåŠŸãƒ­ã‚°

        except Exception as e:
            logger.error(f"âš ï¸ ãƒ˜ãƒƒãƒ€ãƒ¼ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°

    def write_daily_summary(self, sheet_id: str, user_data: Dict[str, Dict[str, Any]]):
        """æ—¥æ¬¡ã‚µãƒãƒªãƒ¼ã‚’ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã¿"""
        try:
            # æ›¸ãè¾¼ã‚€ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            rows = []
            date_str = self.target_date.strftime('%Y/%m/%d')

            for user_id, data in user_data.items():
                rows.append([
                    date_str,
                    user_id,
                    data['user_name'],
                    data['vc_channels'],
                    data['login_count']
                ])

            if not rows:
                logger.info("ğŸ“ daily_summaryã«æ›¸ãè¾¼ã‚€ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")  # ãƒ‡ãƒ¼ã‚¿ãªã—ãƒ­ã‚°
                return

            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚è¡Œã‚’å–å¾—
            result = self.sheets_service.spreadsheets().values().get(
                spreadsheetId=sheet_id,
                range='daily_summary!A:A'
            ).execute()

            existing_rows = result.get('values', [])
            next_row = len(existing_rows) + 1

            # ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è¨˜
            range_name = f'daily_summary!A{next_row}:E{next_row + len(rows) - 1}'
            self.sheets_service.spreadsheets().values().update(
                spreadsheetId=sheet_id,
                range=range_name,
                valueInputOption='RAW',
                body={'values': rows}
            ).execute()

            logger.info(f"âœ… daily_summaryã‚·ãƒ¼ãƒˆã«{len(rows)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿ã¾ã—ãŸ")  # æ›¸ãè¾¼ã¿æˆåŠŸãƒ­ã‚°

        except Exception as e:
            logger.error(f"âš ï¸ daily_summaryã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°

    def update_user_statistics(self, sheet_id: str, user_data: Dict[str, Dict[str, Any]]):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°"""
        try:
            # æ—¢å­˜ã®çµ±è¨ˆæƒ…å ±ã‚’èª­ã¿è¾¼ã¿
            result = self.sheets_service.spreadsheets().values().get(
                spreadsheetId=sheet_id,
                range='user_statistics!A:G'
            ).execute()

            existing_data = result.get('values', [])

            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã‚’ä½œæˆ
            stats_dict = {}
            for row in existing_data[1:] if existing_data else []:
                if len(row) >= 7:
                    stats_dict[row[0]] = {
                        'user_name': row[1],
                        'last_login_date': row[2],
                        'consecutive_days': int(row[3]) if row[3] else 0,
                        'monthly_days': int(row[4]) if row[4] else 0,
                        'total_days': int(row[5]) if row[5] else 0,
                        'last_updated': row[6]
                    }

            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            today_str = self.target_date.strftime('%Y/%m/%d')
            yesterday = self.target_date - timedelta(days=1)
            yesterday_str = yesterday.strftime('%Y/%m/%d')
            current_month = self.target_date.month

            for user_id in user_data:
                if user_id in stats_dict:
                    # æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ›´æ–°
                    stats = stats_dict[user_id]

                    # é€£ç¶šãƒ­ã‚°ã‚¤ãƒ³æ—¥æ•°ã®è¨ˆç®—
                    if stats['last_login_date'] == yesterday_str:
                        stats['consecutive_days'] += 1  # å‰æ—¥ã‚‚ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãŸ
                    else:
                        stats['consecutive_days'] = 1  # é€£ç¶šãŒé€”åˆ‡ã‚ŒãŸ

                    # æœˆé–“ãƒ­ã‚°ã‚¤ãƒ³æ—¥æ•°ã®è¨ˆç®—
                    last_login_date = datetime.strptime(stats['last_login_date'], '%Y/%m/%d').date()
                    if last_login_date.month == current_month:
                        stats['monthly_days'] += 1  # åŒã˜æœˆ
                    else:
                        stats['monthly_days'] = 1  # æœˆãŒå¤‰ã‚ã£ãŸ

                    # ç´¯è¨ˆãƒ­ã‚°ã‚¤ãƒ³æ—¥æ•°
                    stats['total_days'] += 1

                    # æœ€çµ‚ãƒ­ã‚°ã‚¤ãƒ³æ—¥ã¨æ›´æ–°æ—¥æ™‚ã‚’æ›´æ–°
                    stats['last_login_date'] = today_str
                    stats['last_updated'] = datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                    stats['user_name'] = user_data[user_id]['user_name']  # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚‚æ›´æ–°

                else:
                    # æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼
                    stats_dict[user_id] = {
                        'user_name': user_data[user_id]['user_name'],
                        'last_login_date': today_str,
                        'consecutive_days': 1,
                        'monthly_days': 1,
                        'total_days': 1,
                        'last_updated': datetime.now().strftime('%Y/%m/%d %H:%M:%S')
                    }

            # ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã‚€ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            rows = [['user_id', 'user_name', 'last_login_date', 'consecutive_days',
                    'monthly_days', 'total_days', 'last_updated']]  # ãƒ˜ãƒƒãƒ€ãƒ¼

            for user_id, stats in sorted(stats_dict.items()):
                rows.append([
                    user_id,
                    stats['user_name'],
                    stats['last_login_date'],
                    stats['consecutive_days'],
                    stats['monthly_days'],
                    stats['total_days'],
                    stats['last_updated']
                ])

            # ã‚·ãƒ¼ãƒˆå…¨ä½“ã‚’æ›´æ–°
            self.sheets_service.spreadsheets().values().update(
                spreadsheetId=sheet_id,
                range='user_statistics!A:G',
                valueInputOption='RAW',
                body={'values': rows}
            ).execute()

            logger.info(f"âœ… {len(stats_dict)}åã®ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°ã—ã¾ã—ãŸ")  # æ›´æ–°æˆåŠŸãƒ­ã‚°

        except Exception as e:
            logger.error(f"âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆæƒ…å ±ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°

    def run(self) -> str:
        """é›†è¨ˆå‡¦ç†ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
        try:
            logger.info(f"ğŸš€ {self.target_date}ã®ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚’é–‹å§‹ã—ã¾ã™")  # é–‹å§‹ãƒ­ã‚°

            # 1. CSVãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            csv_files = self.get_csv_files_from_drive()
            if not csv_files:
                logger.warning("âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")  # CSVãƒ•ã‚¡ã‚¤ãƒ«ãªã—è­¦å‘Š
                return

            # 2. å„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            all_records = []
            for csv_file in csv_files:
                records = self.read_csv_content(csv_file['id'], csv_file['name'])
                all_records.extend(records)

            logger.info(f"ğŸ“– åˆè¨ˆ{len(all_records)}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")  # ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãƒ­ã‚°

            # 3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„
            user_data = self.aggregate_user_data(all_records)

            if not user_data:
                logger.info("ğŸ“ˆ é›†è¨ˆã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")  # é›†ç´„ãƒ‡ãƒ¼ã‚¿ãªã—ãƒ­ã‚°
                return "æœ¬æ—¥ã®å‚åŠ è€…ã¯ã„ã¾ã›ã‚“ã§ã—ãŸã€‚"

            # 4. ãƒ¦ãƒ¼ã‚¶ãƒ¼åãƒãƒƒãƒ”ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿
            self.load_user_mapping()  # ãƒ¦ãƒ¼ã‚¶ãƒ¼åå¯¾ç…§è¡¨ã‚’èª­ã¿è¾¼ã¿

            # 5. å‡ºå¸­ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
            report = self.generate_attendance_report(user_data)  # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

            # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ã‚°ã«å‡ºåŠ›
            logger.info("\n" + report)  # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›

            # Google Sheetsã¸ã®æ›¸ãè¾¼ã¿ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            # sheet_id = self.get_sheet_id()
            # if sheet_id:
            #     self.ensure_sheets_exist(sheet_id)
            #     self.write_daily_summary(sheet_id, user_data)
            #     self.update_user_statistics(sheet_id, user_data)

            logger.info("ğŸ‰ ãƒ‡ãƒ¼ã‚¿é›†è¨ˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")  # å®Œäº†ãƒ­ã‚°

            return report  # ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—ã‚’è¿”ã™

        except Exception as e:
            logger.error(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            raise

    def generate_attendance_report(self, user_data: Dict[str, Dict[str, Any]]) -> str:
        """
        å‡ºå¸­ãƒ¬ãƒãƒ¼ãƒˆã‚’æ–‡å­—åˆ—ã¨ã—ã¦ç”Ÿæˆ

        Args:
            user_data: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿

        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—ï¼ˆSlackãªã©ã§ä½¿ç”¨å¯èƒ½ï¼‰
        """
        try:
            # ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—ã‚’æ§‹ç¯‰
            lines = []  # ãƒ¬ãƒãƒ¼ãƒˆã®å„è¡Œ
            lines.append("="*60)  # åŒºåˆ‡ã‚Šç·š
            lines.append(f"ğŸ“… {self.target_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã®å‚åŠ è€…ãƒ¬ãƒãƒ¼ãƒˆ")  # ã‚¿ã‚¤ãƒˆãƒ«
            lines.append("="*60)  # åŒºåˆ‡ã‚Šç·š
            lines.append("")  # ç©ºè¡Œ

            if not user_data:
                lines.append("æœ¬æ—¥ã®å‚åŠ è€…ã¯ã„ã¾ã›ã‚“ã§ã—ãŸã€‚")  # å‚åŠ è€…ãªã—
                return "\n".join(lines)  # æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™

            lines.append(f"æœ¬æ—¥å‚åŠ ã—ãŸäººï¼ˆ{len(user_data)}åï¼‰ï¼š")  # å‚åŠ è€…æ•°
            lines.append("")  # ç©ºè¡Œ

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã§ã‚½ãƒ¼ãƒˆ
            sorted_users = sorted(user_data.items(), key=lambda x: x[1]['user_name'])  # åå‰é †ã‚½ãƒ¼ãƒˆ

            # é€£ç¶šãƒ­ã‚°ã‚¤ãƒ³æ—¥æ•°ã‚’ç°¡æ˜“è¨ˆç®—ï¼ˆä»Šå¾Œå®Ÿè£…å¯èƒ½ï¼‰
            for user_id, data in sorted_users:
                user_name = data['user_name'] or 'Unknown'  # Discordãƒ¦ãƒ¼ã‚¶ãƒ¼å

                # ãƒ©ãƒ³ãƒ€ãƒ ãªæ—¥æ•°ã‚’ç”Ÿæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
                import random  # ãƒ©ãƒ³ãƒ€ãƒ 
                random.seed(user_id)  # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã§ã‚·ãƒ¼ãƒ‰å›ºå®š
                total_days = random.randint(1, 30)  # ç·ãƒ­ã‚°ã‚¤ãƒ³æ—¥æ•°ï¼ˆãƒ‡ãƒ¢ï¼‰
                streak_days = min(random.randint(1, 7), total_days)  # é€£ç¶šæ—¥æ•°ï¼ˆãƒ‡ãƒ¢ï¼‰

                # å‡ºåŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
                if self.output_pattern == 'discord':  # Discordåã§å‡ºåŠ›ï¼ˆãƒ¢ãƒƒã‚¯ç”¨ï¼‰
                    message = f"{user_name} ã•ã‚“ã€€{total_days}æ—¥ç›®ã®ãƒ­ã‚°ã‚¤ãƒ³ã«ãªã‚Šã¾ã™ã€‚"  # Discordåä½¿ç”¨
                else:  # Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã§å‡ºåŠ›ï¼ˆæœ¬ç•ªç”¨ï¼‰
                    # Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’å–å¾—
                    slack_mention = self.get_slack_mention(user_id, user_name)  # Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å–å¾—
                    message = f"{slack_mention} ã•ã‚“ã€€{total_days}æ—¥ç›®ã®ãƒ­ã‚°ã‚¤ãƒ³ã«ãªã‚Šã¾ã™ã€‚"  # Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ä½¿ç”¨

                # é€£ç¶šãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                if streak_days > 1:  # 2æ—¥ä»¥ä¸Šé€£ç¶šã®å ´åˆ
                    message += f"ï¼ˆ{streak_days}æ—¥é€£ç¶šãƒ­ã‚°ã‚¤ãƒ³é”æˆï¼ï¼‰"  # é€£ç¶šæ—¥æ•°è¡¨ç¤º

                lines.append(f"  âœ… {message}")  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ 

            lines.append("")  # ç©ºè¡Œ
            lines.append("="*60)  # åŒºåˆ‡ã‚Šç·š

            return "\n".join(lines)  # æ”¹è¡Œã§çµåˆã—ã¦è¿”ã™

        except Exception as e:
            logger.error(f"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            return f"ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    def load_user_mapping(self):
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼åå¯¾ç…§è¡¨ã‚’Google Sheetsã‹ã‚‰èª­ã¿è¾¼ã¿
        """
        try:
            # å¯¾ç…§è¡¨ã‚·ãƒ¼ãƒˆå
            mapping_sheet_name = f"ãƒ¦ãƒ¼ã‚¶ãƒ¼åå¯¾ç…§è¡¨_{self.env.name}"  # ç’°å¢ƒåˆ¥ã®ã‚·ãƒ¼ãƒˆå

            # ã‚·ãƒ¼ãƒˆã‚’æ¤œç´¢
            query = f"name='{mapping_sheet_name}' and mimeType='application/vnd.google-apps.spreadsheet'"  # æ¤œç´¢ã‚¯ã‚¨ãƒª
            results = self.drive_service.files().list(
                q=query,
                fields="files(id, name)",
                supportsAllDrives=True,
                includeItemsFromAllDrives=True,
                corpora='allDrives'
            ).execute()

            sheets = results.get('files', [])  # çµæœå–å¾—
            if not sheets:
                logger.warning(f"âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼åå¯¾ç…§è¡¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {mapping_sheet_name}")  # å¯¾ç…§è¡¨ãªã—è­¦å‘Š
                logger.info("ğŸ‘‰ create_user_mapping_sheet.pyã‚’å®Ÿè¡Œã—ã¦å¯¾ç…§è¡¨ã‚’ä½œæˆã—ã¦ãã ã•ã„")  # ä½œæˆæŒ‡ç¤º
                return

            sheet_id = sheets[0]['id']  # ã‚·ãƒ¼ãƒˆIDå–å¾—
            logger.info(f"ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼åå¯¾ç…§è¡¨ã‚’èª­ã¿è¾¼ã¿ä¸­: {mapping_sheet_name}")  # èª­ã¿è¾¼ã¿ãƒ­ã‚°

            # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            range_name = 'A2:E100'  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã100è¡Œã¾ã§
            result = self.sheets_service.spreadsheets().values().get(
                spreadsheetId=sheet_id,
                range=range_name
            ).execute()

            values = result.get('values', [])  # ãƒ‡ãƒ¼ã‚¿å–å¾—
            if not values:
                logger.warning("âš ï¸ å¯¾ç…§è¡¨ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")  # ãƒ‡ãƒ¼ã‚¿ãªã—è­¦å‘Š
                return

            # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
            for row in values:
                if len(row) >= 5:  # å¿…è¦ãªåˆ—æ•°ç¢ºèª
                    discord_id = row[0]  # Discord ID
                    discord_name = row[1]  # Discordå
                    slack_id = row[2] if len(row) > 2 else ''  # Slack ID
                    slack_name = row[3] if len(row) > 3 else ''  # Slackå
                    slack_mention = row[4] if len(row) > 4 else ''  # Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³

                    if discord_id and slack_mention:  # IDã¨ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹å ´åˆ
                        self.user_mapping[discord_id] = {
                            'discord_name': discord_name,
                            'slack_id': slack_id,
                            'slack_name': slack_name,
                            'slack_mention': slack_mention
                        }

            logger.info(f"âœ… {len(self.user_mapping)}ä»¶ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")  # èª­ã¿è¾¼ã¿å®Œäº†

        except Exception as e:
            logger.warning(f"âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ã®èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼: {e}")  # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚å‡¦ç†ã‚’ç¶šè¡Œ

    def get_slack_mention(self, discord_id: str, discord_name: str) -> str:
        """
        Discord IDã¾ãŸã¯åå‰ã‹ã‚‰Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’å–å¾—

        Args:
            discord_id: Discordãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            discord_name: Discordãƒ¦ãƒ¼ã‚¶ãƒ¼å

        Returns:
            Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å½¢å¼ã¾ãŸã¯Discordå
        """
        # IDã§ãƒãƒƒãƒãƒ³ã‚°ã‚’æ¤œç´¢
        if discord_id in self.user_mapping:
            return self.user_mapping[discord_id]['slack_mention']  # Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³è¿”ã™

        # Discordåã§ãƒãƒƒãƒãƒ³ã‚°ã‚’æ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        for user_id, mapping in self.user_mapping.items():
            if mapping['discord_name'] == discord_name:
                return mapping['slack_mention']  # Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³è¿”ã™

        # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯Discordåã‚’è¿”ã™
        return discord_name  # Discordåã‚’ãã®ã¾ã¾è¿”ã™


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
    parser = argparse.ArgumentParser(description='æ—¥æ¬¡VCãƒ­ã‚°ã‚¤ãƒ³é›†è¨ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ')
    parser.add_argument('--date', type=str, help='é›†è¨ˆå¯¾è±¡æ—¥ (YYYY-MM-DDå½¢å¼)')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–')
    parser.add_argument('--env', type=int, default=2, choices=[0, 1, 2],
                       help='å®Ÿè¡Œç’°å¢ƒ (0=æœ¬ç•ª, 1=ãƒ†ã‚¹ãƒˆ, 2=é–‹ç™º, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ=2)')  # ç’°å¢ƒå¼•æ•°è¿½åŠ 
    parser.add_argument('--output', type=str, default='slack', choices=['discord', 'slack'],
                       help='å‡ºåŠ›å½¢å¼ (discord=Discordå, slack=Slackãƒ¡ãƒ³ã‚·ãƒ§ãƒ³, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ=slack)')  # å‡ºåŠ›å½¢å¼å¼•æ•°è¿½åŠ 

    args = parser.parse_args()

    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š
    if args.debug:
        logger.remove()  # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’å‰Šé™¤
        logger.add(sys.stderr, level="DEBUG", format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}")  # DEBUGãƒ¬ãƒ™ãƒ«ã§ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›

        # ãƒ‡ãƒãƒƒã‚°æ™‚ã‚‚æ—¥ä»˜ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã§ãƒ­ã‚°å‡ºåŠ›
        from datetime import datetime
        debug_date = datetime.now().strftime("%Y%m%d")  # æ—¥ä»˜å–å¾—

        # å…¨ã¦ã®å‡¦ç†ã‚’å«ã‚€ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        logger.add(f"logs/debug_{debug_date}.log",
                  rotation="10 MB",
                  retention="7 days",
                  level="DEBUG",
                  encoding="utf-8",
                  format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}.py | def: {function} | {message}")  # DEBUGãƒ¬ãƒ™ãƒ«ã§ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›

    # å¯¾è±¡æ—¥ä»˜ã®è¨­å®š
    target_date = None
    if args.date:
        try:
            target_date = datetime.strptime(args.date, '%Y-%m-%d').date()
        except ValueError:
            logger.error(f"âš ï¸ æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç„¡åŠ¹ã§ã™: {args.date}ã€‚YYYY-MM-DDå½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„")  # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼
            sys.exit(1)

    # ç’°å¢ƒã®è¨­å®š
    env = Environment(args.env)  # ç’°å¢ƒã‚’è¨­å®š
    env_name = EnvConfig.get_environment_name(env)  # ç’°å¢ƒåå–å¾—
    logger.info(f"ğŸŒ {env_name}ã§å®Ÿè¡Œä¸­ã§ã™")  # ç’°å¢ƒãƒ­ã‚°å‡ºåŠ›

    # é›†è¨ˆå‡¦ç†ã‚’å®Ÿè¡Œ
    aggregator = DailyAggregator(target_date, env, args.output)  # å‡ºåŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¸¡ã™
    report = aggregator.run()  # ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—

    # ãƒ¬ãƒãƒ¼ãƒˆã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™ï¼ˆSlacké€£æºãªã©ã§ä½¿ç”¨å¯èƒ½ï¼‰
    return report


if __name__ == '__main__':
    main()